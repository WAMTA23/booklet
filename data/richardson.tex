\begin{center}
\textit{Co-Authors: Damian Rouson, Harris Snyder, and Robert Singleterry}
\end{center} 
Modern Fortran empowers developers to express parallel algorithms without directly referencing lower-level parallel programming models. Fortran’s parallel programming features place Fortran within the Partitioned Global Address Space (PGAS) class of languages. Prior to the introduction of the parallel features of modern Fortran, most parallel scientific programs hardwired compiler directives (pragmas), run-time library procedure calls, and compiler-specific language extensions directly into the Fortran source code. Examples include Message Passing Interface (MPI) procedure calls, OpenMP compiler directives and compiler-specific CUDA Fortran. For data-parallel problems, application developers typically find it straightforward to implement their own parallel algorithms. Software that perform complex, heterogeneous, staged calculations, however, pose a much greater challenge. Such applications require careful coordination of the calculations of task dependencies as prescribed by directed acyclic graphs. In these cases, rolling one’s own solution proves difficult and finding a customizable framework to extend becomes attractive.

To the best of our knowledge, FEATS is the first framework of its kind in modern Fortran. This paper discusses the techniques used in implementing FEATS. It describes the methods used for coordinating execution of tasks between images. It also describes the methods used to communicate data between tasks. The paper presents the positive and negative aspects of the approach, along with the beneficial features and shortcomings of the Fortran language. We describe what a user of the framework must
provide, and how this is done, including presenting a working example.