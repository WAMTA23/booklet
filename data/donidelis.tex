Numerous benchmarking efforts have been made to compare both qualitatively and quantitatively, the large variety of asynchronous runtime systems available in the community. A standardized benchmarking solution, Task Bench, is being deployed in this research to explore the shared memory concurrency performance between two analogous Asynchronous Many-Task (AMT) systems: OpenMP and a C++ standard library for parallelism and concurrency (HPX). In this work, we focus on the shared memory features of HPX and neglect the distributed memory features. Based on the results of this analysis, we expose the characteristics relative to both interfaces and scheduling mechanisms of each system that inhibit performance, and we present the corresponding improvements applied. Efficiency of the implemented testing ground, proper interfacing for asynchrony, and thorough examination of the scheduling can lead to significant performance gain in both systems and showcase shifting of any original measurements. In this research, we are not only trying to emphasize on the on-node performance of the two AMTs on top of Task Bench, but we are also trying to provide the community with a state-of-the-art guidance on how to minimize overheads in parallel code and emphasize the broadness of potential performance barriers.