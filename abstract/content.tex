As our compute capacity grows, science simulations are not only becoming bigger, but more complex. Simulations are carried out at multiple scales and using multiple kinds of physics at once. Boundaries are irregular, grids are irregular, computational domains can be dynamic and complex. In such scenarios, the ideal way to parallelize often cannot be statically determined. At the same time, hardware is becoming more heterogeneous and difficult to program. Increasingly, scientists are turning to asynchronous, dynamic parallelism in order to make the best use of increasingly challenging hardware. As a result, numerous frameworks, platforms, and specialized languages have sprung up to answer this need.

The objectives of this workshop are to bring together experts in asynchronous many-task frameworks, developers of science codes, performance experts, and hardware vendors to discuss the state-of-the-art techniques needed to program, analyze, benchmark, and profile these codes to achieve maximum performance possible from modern machines. This workshop will promote a dialogue between these communities, and help identify challenges and opportunities for advancement in all the disciplines they represent.

\section*{Organizing Committee}
\begin{itemize}
\item Patrick Diehl, Louisiana State University
\item Hartmut Kaiser, Louisiana State University
\item Steven R. Brandt, Louisiana State University
\end{itemize}

\section*{Scientific committee}
\begin{itemize}
\item Erwin Laure, Max Planck Computing \& Data Facility, Germany
\item Christoph Junghans, Los Alamos National Laboratory
\item Bryce Adelstein Lelbach, NVIDIA
\item Thomas Fahringer, University of Innsbruck, Austria
\item Laxmikant V. Kale,  University of Illinois at Urbana-Champaign
\item Alex Aiken, Stanford
\item Brad Chamberlain, HPE
\end{itemize}

\section*{Logistics}
\begin{itemize}
\item Karen Jones and Jennifer Claudet, Louisiana State University
\end{itemize}
